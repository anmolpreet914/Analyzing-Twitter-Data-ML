{"cells":[{"cell_type":"code","execution_count":23,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-08T21:24:27.760669Z","iopub.status.busy":"2024-07-08T21:24:27.760200Z","iopub.status.idle":"2024-07-08T21:24:28.301422Z","shell.execute_reply":"2024-07-08T21:24:28.300123Z","shell.execute_reply.started":"2024-07-08T21:24:27.760632Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","#import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","#    for filename in filenames:\n","#        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:18.561571Z","iopub.status.busy":"2024-07-09T12:47:18.561129Z","iopub.status.idle":"2024-07-09T12:47:18.567783Z","shell.execute_reply":"2024-07-09T12:47:18.566541Z","shell.execute_reply.started":"2024-07-09T12:47:18.561535Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","from imblearn.pipeline import make_pipeline\n","from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:22.611932Z","iopub.status.busy":"2024-07-09T12:47:22.610917Z","iopub.status.idle":"2024-07-09T12:47:23.864447Z","shell.execute_reply":"2024-07-09T12:47:23.863249Z","shell.execute_reply.started":"2024-07-09T12:47:22.611880Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>clean_text_processed</th>\n","      <th>Mood</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>['adrianrusso', 'innovation', 'lab', 'official...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>['open', 'aws', 'asia', 'pacific', 'seoul', 'r...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>['beginner', 'guide', 'scaling', 'million', 'u...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>['bridging', 'aws', 'azure', 'environment', 'v...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>['elk', 'aws', 'elasticsearch', 'service', 'el...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                               clean_text_processed  Mood\n","0           0  ['adrianrusso', 'innovation', 'lab', 'official...     0\n","1           1  ['open', 'aws', 'asia', 'pacific', 'seoul', 'r...     0\n","2           2  ['beginner', 'guide', 'scaling', 'million', 'u...     0\n","3           3  ['bridging', 'aws', 'azure', 'environment', 'v...     0\n","4           4  ['elk', 'aws', 'elasticsearch', 'service', 'el...     0"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Load cleaned dataset\n","#df = pd.read_csv('/kaggle/input/twitterdata/tweets-engagement-metrics.csv')\n","df = pd.read_csv(r\"D:\\Jojo\\LAMBTON\\3. Spring May2024\\1. BDM 3035 - Big Data Capstone Project\\Capstone Project\\notebooks\\Clean data.csv\")\n","\n","# Display the first 5 entries of the DataFrame\n","df.head(5)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:28.370830Z","iopub.status.busy":"2024-07-09T12:47:28.370440Z","iopub.status.idle":"2024-07-09T12:47:28.395307Z","shell.execute_reply":"2024-07-09T12:47:28.394159Z","shell.execute_reply.started":"2024-07-09T12:47:28.370801Z"},"trusted":true},"outputs":[],"source":["df = df.drop('Unnamed: 0', axis=1)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:38.088224Z","iopub.status.busy":"2024-07-09T12:47:38.087761Z","iopub.status.idle":"2024-07-09T12:47:38.128580Z","shell.execute_reply":"2024-07-09T12:47:38.127211Z","shell.execute_reply.started":"2024-07-09T12:47:38.088187Z"},"trusted":true},"outputs":[],"source":["#Like over Mood\n","\n","#df['Mood'] = df['Sentiment'].apply(lambda x: 'Positive' if x > 0 else ('Neutral' if x==0 else 'Negative'))\n","#df['Mood']"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:40.494222Z","iopub.status.busy":"2024-07-09T12:47:40.493818Z","iopub.status.idle":"2024-07-09T12:47:40.515601Z","shell.execute_reply":"2024-07-09T12:47:40.514180Z","shell.execute_reply.started":"2024-07-09T12:47:40.494189Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Mood\n"," 0    64209\n"," 1    26507\n","-1     5292\n","Name: count, dtype: int64"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["mood_counts = df['Mood'].value_counts()\n","mood_counts"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:43.115865Z","iopub.status.busy":"2024-07-09T12:47:43.115475Z","iopub.status.idle":"2024-07-09T12:47:43.134337Z","shell.execute_reply":"2024-07-09T12:47:43.132966Z","shell.execute_reply.started":"2024-07-09T12:47:43.115836Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_text_processed</th>\n","      <th>Mood</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['adrianrusso', 'innovation', 'lab', 'official...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>['open', 'aws', 'asia', 'pacific', 'seoul', 'r...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>['beginner', 'guide', 'scaling', 'million', 'u...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>['bridging', 'aws', 'azure', 'environment', 'v...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>['elk', 'aws', 'elasticsearch', 'service', 'el...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                clean_text_processed  Mood\n","0  ['adrianrusso', 'innovation', 'lab', 'official...     0\n","1  ['open', 'aws', 'asia', 'pacific', 'seoul', 'r...     0\n","2  ['beginner', 'guide', 'scaling', 'million', 'u...     0\n","3  ['bridging', 'aws', 'azure', 'environment', 'v...     0\n","4  ['elk', 'aws', 'elasticsearch', 'service', 'el...     0"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["df[['clean_text_processed', 'Mood']].head(5)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:46.517267Z","iopub.status.busy":"2024-07-09T12:47:46.516869Z","iopub.status.idle":"2024-07-09T12:47:46.697709Z","shell.execute_reply":"2024-07-09T12:47:46.696642Z","shell.execute_reply.started":"2024-07-09T12:47:46.517233Z"},"trusted":true},"outputs":[],"source":["#from sklearn.preprocessing import LabelEncoder\n","\n","#le_model = LabelEncoder()\n","#df['Label'] = le_model.fit_transform(df['Mood'])\n","#df"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:49.981133Z","iopub.status.busy":"2024-07-09T12:47:49.979845Z","iopub.status.idle":"2024-07-09T12:47:49.992212Z","shell.execute_reply":"2024-07-09T12:47:49.990980Z","shell.execute_reply.started":"2024-07-09T12:47:49.981039Z"},"trusted":true},"outputs":[],"source":["# 2 = Positive\n","# 1 = Neutral\n","# 0 = Negative\n","#mood_counts = df['Label'].value_counts()\n","#mood_counts"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:52.401299Z","iopub.status.busy":"2024-07-09T12:47:52.400708Z","iopub.status.idle":"2024-07-09T12:47:52.415827Z","shell.execute_reply":"2024-07-09T12:47:52.414504Z","shell.execute_reply.started":"2024-07-09T12:47:52.401195Z"},"trusted":true},"outputs":[],"source":["#testing_target = pd.Series([df['Label']])\n","#testing_target"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:54.776415Z","iopub.status.busy":"2024-07-09T12:47:54.775880Z","iopub.status.idle":"2024-07-09T12:47:54.787164Z","shell.execute_reply":"2024-07-09T12:47:54.785863Z","shell.execute_reply.started":"2024-07-09T12:47:54.776366Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0        ['adrianrusso', 'innovation', 'lab', 'official...\n","1        ['open', 'aws', 'asia', 'pacific', 'seoul', 'r...\n","2        ['beginner', 'guide', 'scaling', 'million', 'u...\n","3        ['bridging', 'aws', 'azure', 'environment', 'v...\n","4        ['elk', 'aws', 'elasticsearch', 'service', 'el...\n","                               ...                        \n","96003    ['springcoil', 'anyone', 'good', 'workflow', '...\n","96004    ['linuxacademycom', 'aws', 'csa', 'associate',...\n","96005    ['curious', 'benthompson', 'change', 'opinion'...\n","96006    ['awscloud', 'new', 'aws', 'staup', 'blog', 's...\n","96007    ['ictafrica', 'top', 'paying', 'ceifications',...\n","Name: clean_text_processed, Length: 96008, dtype: object"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["testing_text = pd.Series(df['clean_text_processed'])\n","testing_text"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:47:59.830687Z","iopub.status.busy":"2024-07-09T12:47:59.829639Z","iopub.status.idle":"2024-07-09T12:50:56.931748Z","shell.execute_reply":"2024-07-09T12:50:56.930325Z","shell.execute_reply.started":"2024-07-09T12:47:59.830643Z"},"trusted":true},"outputs":[],"source":["#from sklearn.feature_extraction.text import TfidfVectorizer\n","#from sklearn.model_selection import train_test_split\n","#from imblearn.over_sampling import SMOTE\n","\n","# Initialize TF-IDF Vectorizer\n","tfidf = TfidfVectorizer(max_features=10000, stop_words='english')\n","\n","# Convert text data into numerical features\n","X = tfidf.fit_transform(df['clean_text_processed'])\n","\n","# Ensure y is a 1D array of labels\n","y = df['Mood'].values\n","\n","# Initialize SMOTE\n","smote = SMOTE(random_state=777, k_neighbors=1)\n","\n","# Apply SMOTE to the training data\n","X_train_smote, y_train_smote = smote.fit_resample(X, y)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:53:34.430365Z","iopub.status.busy":"2024-07-09T12:53:34.429857Z","iopub.status.idle":"2024-07-09T12:53:47.984147Z","shell.execute_reply":"2024-07-09T12:53:47.982916Z","shell.execute_reply.started":"2024-07-09T12:53:34.430327Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aa</th>\n","      <th>aaa</th>\n","      <th>aaand</th>\n","      <th>aalvarezgarcia</th>\n","      <th>aampws</th>\n","      <th>aapl</th>\n","      <th>aaron</th>\n","      <th>aaronmsaunders</th>\n","      <th>aaronwoodman</th>\n","      <th>ab</th>\n","      <th>...</th>\n","      <th>zone</th>\n","      <th>zookeeper</th>\n","      <th>zoomdata</th>\n","      <th>zoomdatas</th>\n","      <th>zoran</th>\n","      <th>zos</th>\n","      <th>zu</th>\n","      <th>zwlf</th>\n","      <th>zynga</th>\n","      <th>zzp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>192622</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>192623</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>192624</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>192625</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>192626</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>192627 rows × 10000 columns</p>\n","</div>"],"text/plain":["         aa  aaa  aaand  aalvarezgarcia  aampws  aapl  aaron  aaronmsaunders  \\\n","0       0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","1       0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","2       0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","3       0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","4       0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","...     ...  ...    ...             ...     ...   ...    ...             ...   \n","192622  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","192623  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","192624  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","192625  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","192626  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","\n","        aaronwoodman   ab  ...  zone  zookeeper  zoomdata  zoomdatas  zoran  \\\n","0                0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","1                0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","2                0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","3                0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","4                0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","...              ...  ...  ...   ...        ...       ...        ...    ...   \n","192622           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","192623           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","192624           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","192625           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","192626           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","\n","        zos   zu  zwlf  zynga  zzp  \n","0       0.0  0.0   0.0    0.0  0.0  \n","1       0.0  0.0   0.0    0.0  0.0  \n","2       0.0  0.0   0.0    0.0  0.0  \n","3       0.0  0.0   0.0    0.0  0.0  \n","4       0.0  0.0   0.0    0.0  0.0  \n","...     ...  ...   ...    ...  ...  \n","192622  0.0  0.0   0.0    0.0  0.0  \n","192623  0.0  0.0   0.0    0.0  0.0  \n","192624  0.0  0.0   0.0    0.0  0.0  \n","192625  0.0  0.0   0.0    0.0  0.0  \n","192626  0.0  0.0   0.0    0.0  0.0  \n","\n","[192627 rows x 10000 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(X_train_smote.todense(), columns=tfidf.get_feature_names_out())"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T21:21:01.755892Z","iopub.status.busy":"2024-07-08T21:21:01.755304Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aa</th>\n","      <th>aaa</th>\n","      <th>aaand</th>\n","      <th>aalvarezgarcia</th>\n","      <th>aampws</th>\n","      <th>aapl</th>\n","      <th>aaron</th>\n","      <th>aaronmsaunders</th>\n","      <th>aaronwoodman</th>\n","      <th>ab</th>\n","      <th>...</th>\n","      <th>zone</th>\n","      <th>zookeeper</th>\n","      <th>zoomdata</th>\n","      <th>zoomdatas</th>\n","      <th>zoran</th>\n","      <th>zos</th>\n","      <th>zu</th>\n","      <th>zwlf</th>\n","      <th>zynga</th>\n","      <th>zzp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>64204</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>64205</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>64206</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>64207</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>64208</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>64209 rows × 10000 columns</p>\n","</div>"],"text/plain":["        aa  aaa  aaand  aalvarezgarcia  aampws  aapl  aaron  aaronmsaunders  \\\n","0      0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","1      0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","2      0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","3      0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","4      0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","...    ...  ...    ...             ...     ...   ...    ...             ...   \n","64204  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","64205  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","64206  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","64207  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","64208  0.0  0.0    0.0             0.0     0.0   0.0    0.0             0.0   \n","\n","       aaronwoodman   ab  ...  zone  zookeeper  zoomdata  zoomdatas  zoran  \\\n","0               0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","1               0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","2               0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","3               0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","4               0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","...             ...  ...  ...   ...        ...       ...        ...    ...   \n","64204           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","64205           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","64206           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","64207           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","64208           0.0  0.0  ...   0.0        0.0       0.0        0.0    0.0   \n","\n","       zos   zu  zwlf  zynga  zzp  \n","0      0.0  0.0   0.0    0.0  0.0  \n","1      0.0  0.0   0.0    0.0  0.0  \n","2      0.0  0.0   0.0    0.0  0.0  \n","3      0.0  0.0   0.0    0.0  0.0  \n","4      0.0  0.0   0.0    0.0  0.0  \n","...    ...  ...   ...    ...  ...  \n","64204  0.0  0.0   0.0    0.0  0.0  \n","64205  0.0  0.0   0.0    0.0  0.0  \n","64206  0.0  0.0   0.0    0.0  0.0  \n","64207  0.0  0.0   0.0    0.0  0.0  \n","64208  0.0  0.0   0.0    0.0  0.0  \n","\n","[64209 rows x 10000 columns]"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(X_train_smote.todense()[y_train_smote == 0], columns=tfidf.get_feature_names_out())"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:54:01.391048Z","iopub.status.busy":"2024-07-09T12:54:01.390638Z","iopub.status.idle":"2024-07-09T12:54:01.403977Z","shell.execute_reply":"2024-07-09T12:54:01.402493Z","shell.execute_reply.started":"2024-07-09T12:54:01.391016Z"},"trusted":true},"outputs":[],"source":["tvec = TfidfVectorizer(stop_words='english', max_features=100000, ngram_range=(1, 3))\n","lr = LogisticRegression()\n","\n","SMOTE_pipeline = make_pipeline(tvec, SMOTE(random_state=777),lr)\n","\n","def lr_cv(splits, X, Y, pipeline, average_method):\n","    \n","    kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=777)\n","    accuracy = []\n","    precision = []\n","    recall = []\n","    f1 = []\n","    for train, test in kfold.split(X, Y):\n","        lr_fit = pipeline.fit(X[train], Y[train])\n","        prediction = lr_fit.predict(X[test])\n","        scores = lr_fit.score(X[test],Y[test])\n","        \n","        accuracy.append(scores * 100)\n","        precision.append(precision_score(Y[test], prediction, average=average_method)*100)\n","        print('              negative    neutral     positive')\n","        print('precision:',precision_score(Y[test], prediction, average=None))\n","        recall.append(recall_score(Y[test], prediction, average=average_method)*100)\n","        print('recall:   ',recall_score(Y[test], prediction, average=None))\n","        f1.append(f1_score(Y[test], prediction, average=average_method)*100)\n","        print('f1 score: ',f1_score(Y[test], prediction, average=None))\n","        print('-'*50)\n","\n","    #print(\"accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n","    #print(\"precision: %.2f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n","    #print(\"recall: %.2f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n","    #print(\"f1 score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))\n","    \n","    print(\"accuracy: %.2f%%\" % (np.mean(accuracy)))\n","    print(\"precision: %.2f%%\" % (np.mean(precision)))\n","    print(\"recall: %.2f%%\" % (np.mean(recall)))\n","    print(\"f1 score: %.2f%%\" % (np.mean(f1)))"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T12:54:07.709520Z","iopub.status.busy":"2024-07-09T12:54:07.709116Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Jojo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"name":"stdout","output_type":"stream","text":["              negative    neutral     positive\n","precision: [0.65821596 0.95435039 0.91059068]\n","recall:    [0.79478458 0.94552166 0.8932775 ]\n","f1 score:  [0.72008218 0.94991551 0.90185101]\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Jojo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"name":"stdout","output_type":"stream","text":["              negative    neutral     positive\n","precision: [0.68574154 0.95972393 0.91453382]\n","recall:    [0.81519274 0.94855861 0.90583975]\n","f1 score:  [0.74488474 0.95410861 0.91016602]\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Jojo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"name":"stdout","output_type":"stream","text":["              negative    neutral     positive\n","precision: [0.67037216 0.95581856 0.90899713]\n","recall:    [0.78628118 0.94711022 0.89767968]\n","f1 score:  [0.72371511 0.95144446 0.90330296]\n","--------------------------------------------------\n","accuracy: 92.56%\n","precision: 84.65%\n","recall: 88.16%\n","f1 score: 86.22%\n"]}],"source":["lr_cv(3, df.clean_text_processed, df.Mood, SMOTE_pipeline, 'macro')"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T22:18:02.808938Z","iopub.status.busy":"2024-07-08T22:18:02.808481Z","iopub.status.idle":"2024-07-08T22:18:21.361990Z","shell.execute_reply":"2024-07-08T22:18:21.360655Z","shell.execute_reply.started":"2024-07-08T22:18:02.808906Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          -1       0.91      0.97      0.94     12777\n","           0       0.94      0.92      0.93     12793\n","           1       0.93      0.90      0.91     12956\n","\n","    accuracy                           0.93     38526\n","   macro avg       0.93      0.93      0.93     38526\n","weighted avg       0.93      0.93      0.93     38526\n","\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_train_smote, y_train_smote, test_size=0.2, random_state=42)\n","\n","# Initialize Logistic Regression model\n","model = LogisticRegression(max_iter=1000, random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Evaluate the model\n","y_pred = model.predict(X_test)\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T22:25:14.372355Z","iopub.status.busy":"2024-07-08T22:25:14.371924Z","iopub.status.idle":"2024-07-08T22:25:14.381583Z","shell.execute_reply":"2024-07-08T22:25:14.380201Z","shell.execute_reply.started":"2024-07-08T22:25:14.372318Z"},"trusted":true},"outputs":[],"source":["import pickle\n","\n","# Save the model to a pickle file\n","with open('sentiment_model.pkl', 'wb') as f:\n","    pickle.dump(model, f)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5356242,"sourceId":8908222,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
